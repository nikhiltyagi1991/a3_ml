{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ei4x8huviRAe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import random, pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "#svm imports\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Neural net import\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Linear classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "5G42n9bWiW84",
    "outputId": "564fe76a-26bb-47d3-c2f2-03960994473d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples\t 60000\n",
      "Number of test instances\t 10000\n",
      "Shape of train_data\t\t (60000, 28, 28)\n",
      "Shape of train_labels\t\t (60000,)\n",
      "Shape of test_data\t\t (10000, 28, 28)\n",
      "Shape of test_labels\t\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Fetching MNIST Data (Code from Assignment 1)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_data, train_labels),(test_data, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"Number of training examples\\t\",len(train_data))\n",
    "print(\"Number of test instances\\t\",len(test_data))\n",
    "print(\"Shape of train_data\\t\\t\",train_data.shape)\n",
    "print(\"Shape of train_labels\\t\\t\",train_labels.shape)\n",
    "print(\"Shape of test_data\\t\\t\",test_data.shape)\n",
    "print(\"Shape of test_labels\\t\\t\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Pnn8cUXqkO0-",
    "outputId": "e8d29082-0bbd-4984-dd06-50f2e3825666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of test_data (10000, 784)\n",
      "New shape of train_data (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize test and training data\n",
    "test_data = test_data.reshape(test_data.shape[0], test_data.shape[1] * test_data.shape[2]).astype('float32')\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1] * train_data.shape[2]).astype('float32')\n",
    "\n",
    "print('New shape of test_data', test_data.shape)\n",
    "print('New shape of train_data', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('scaler', StandardScaler()), ('SVM', svm.SVC(kernel='poly'))]\n",
    "pipeline = Pipeline(steps) # define Pipeline object\n",
    "parameters = {'SVM__C':[0.001, 0.1, 100, 10e5], 'SVM__gamma':[10,1,0.1,0.01]}\n",
    "grid = GridSearchCV(pipeline, param_grid=parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(train_data, train_labels)\n",
    "# grid.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sca29j0-iXmg"
   },
   "outputs": [],
   "source": [
    "# SVM Implementation\n",
    "svm_clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "svm_clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm_clf.predict(test_data)\n",
    "acc_svm = ((predictions == test_labels).sum() / test_labels.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D94DaDepjA9n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9477"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(train_data, train_labels)\n",
    "rfc.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfc.predict(test_data)\n",
    "rfc_acc = ((predictions == test_labels).sum() / test_labels.shape[0]) * 100\n",
    "print('accuracy', rfc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JaN6gTMjBgX"
   },
   "outputs": [],
   "source": [
    "# Linear Classifier\n",
    "lc = LogisticRegression(solver='sag', multi_class='ovr')\n",
    "lc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lc.predict(test_data)\n",
    "acc = ((predictions == test_labels).sum() / test_labels.shape[0]) * 100\n",
    "print('accuracy', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_l_tpUBjIX3"
   },
   "outputs": [],
   "source": [
    "# Neural Nets\n",
    "hidden_layers = [(10, 15), (100, 150), (150, 200)]\n",
    "nn = []\n",
    "for hidden_layer in hidden_layers:\n",
    "    neural_net = MLPClassifier(activation=\"logistic\", solver=\"sgd\", hidden_layer_sizes=hidden_layer, random_state=1)\n",
    "    neural_net.fit(train_data, train_labels)\n",
    "    nn.append(neural_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5SH7u0k4GM7b",
    "outputId": "8762beb2-299f-4d70-b637-11408ae9fa9c"
   },
   "outputs": [],
   "source": [
    "for neural_model in nn:\n",
    "    preds = neural_model.predict(test_data)\n",
    "    print('accuracy:', ((preds == test_labels).sum() / test_labels.shape[0])*100)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A3_B00809791.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
