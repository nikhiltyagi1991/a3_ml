{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3 Machine Learning\n",
    "Done By:\n",
    "- Nikhil Tyagi (B00809791)\n",
    "- Aniruddha Chitley (B00808320)\n",
    "- Nitish Bhardwaj (B00811535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ei4x8huviRAe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import random, pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#svm imports\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Neural net import\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Linear classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "5G42n9bWiW84",
    "outputId": "564fe76a-26bb-47d3-c2f2-03960994473d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples\t 60000\n",
      "Number of test instances\t 10000\n",
      "Shape of train_data\t\t (60000, 28, 28)\n",
      "Shape of train_labels\t\t (60000,)\n",
      "Shape of test_data\t\t (10000, 28, 28)\n",
      "Shape of test_labels\t\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Fetching MNIST Data (Code from Assignment 1)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_data, train_labels),(test_data, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"Number of training examples\\t\",len(train_data))\n",
    "print(\"Number of test instances\\t\",len(test_data))\n",
    "print(\"Shape of train_data\\t\\t\",train_data.shape)\n",
    "print(\"Shape of train_labels\\t\\t\",train_labels.shape)\n",
    "print(\"Shape of test_data\\t\\t\",test_data.shape)\n",
    "print(\"Shape of test_labels\\t\\t\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Pnn8cUXqkO0-",
    "outputId": "e8d29082-0bbd-4984-dd06-50f2e3825666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of test_data (10000, 784)\n",
      "New shape of train_data (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize test and training data\n",
    "test_data = test_data.reshape(test_data.shape[0], test_data.shape[1] * test_data.shape[2]).astype('float32')\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1] * train_data.shape[2]).astype('float32')\n",
    "\n",
    "print('New shape of test_data', test_data.shape)\n",
    "print('New shape of train_data', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC - State Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for SVC on MNIST\n",
    "parameters = {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'C':[0.001, 0.1, 100, 10e5],\n",
    "    'gamma':[10,1,0.1,0.01]\n",
    "}\n",
    "grid_svc = GridSearchCV(svm.SVC(), param_grid=parameters, cv=1, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_class_train_data = train_data[np.isin(train_labels, [1,2,3])]\n",
    "three_class_train_labels = train_labels[np.isin(train_labels, [1,2,3])]\n",
    "\n",
    "three_class_test_data = test_data[np.isin(test_labels, [1,2,3])]\n",
    "three_class_test_labels = test_labels[np.isin(test_labels, [1,2,3])]\n",
    "\n",
    "grid_svc.fit(three_class_train_data, three_class_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_svc.score(three_class_test_data, three_class_test_labels))\n",
    "print(grid_svc.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_svc.cv_results_)\n",
    "df.to_pickle('mnist_svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D94DaDepjA9n"
   },
   "outputs": [],
   "source": [
    "# Random Forests, grid search to find best parameter and run cross validation\n",
    "parameters = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "}\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(), param_grid=parameters, cv=2, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696\n",
      "{'max_depth': 110, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "print(grid_rfc.score(test_data, test_labels))\n",
    "print(grid_rfc.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_rfc.cv_results_)\n",
    "df.to_pickle('mnist_rfc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JaN6gTMjBgX"
   },
   "outputs": [],
   "source": [
    "# Linear Classifier\n",
    "parameters = {\n",
    "    'solver': ['sag', 'lbfgs'],\n",
    "    'multi_class': ['ovr']\n",
    "}\n",
    "grid_lr = GridSearchCV(LogisticRegression(), param_grid=parameters, cv=2, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'solver': ['sag', 'lbfgs'], 'multi_class': ['ovr']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202\n",
      "{'multi_class': 'ovr', 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_lr.score(test_data, test_labels))\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_lr.cv_results_)\n",
    "df.to_pickle('mnist_lr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_l_tpUBjIX3"
   },
   "outputs": [],
   "source": [
    "# Neural Nets\n",
    "parameters = {\n",
    "    'activation': ['logistic'],\n",
    "    'solver': ['sgd'],\n",
    "    'max_iter': [100, 300, 500, 1000],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 1],\n",
    "    'hidden_layer_sizes': [(300,),(379,),(500,),(10, 15), (100, 150), (550, 200)]\n",
    "}\n",
    "grid_nn = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nn.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5SH7u0k4GM7b",
    "outputId": "8762beb2-299f-4d70-b637-11408ae9fa9c"
   },
   "outputs": [],
   "source": [
    "print(grid_nn.score(test_data, test_labels))\n",
    "print(grid_nn.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_nn.cv_results_)\n",
    "df.to_pickle('mnist_nn.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A3_B00809791.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
