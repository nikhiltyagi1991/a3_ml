{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3 Machine Learning\n",
    "Done By:\n",
    "- Nikhil Tyagi (B00809791)\n",
    "- Aniruddha Chitley (B00808320)\n",
    "- Nitish Bhardwaj (B00811535)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ei4x8huviRAe"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import random, pdb\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#svm imports\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Neural net import\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#Linear classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "5G42n9bWiW84",
    "outputId": "564fe76a-26bb-47d3-c2f2-03960994473d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples\t 60000\n",
      "Number of test instances\t 10000\n",
      "Shape of train_data\t\t (60000, 28, 28)\n",
      "Shape of train_labels\t\t (60000,)\n",
      "Shape of test_data\t\t (10000, 28, 28)\n",
      "Shape of test_labels\t\t (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Fetching MNIST Data (Code from Assignment 1)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_data, train_labels),(test_data, test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"Number of training examples\\t\",len(train_data))\n",
    "print(\"Number of test instances\\t\",len(test_data))\n",
    "print(\"Shape of train_data\\t\\t\",train_data.shape)\n",
    "print(\"Shape of train_labels\\t\\t\",train_labels.shape)\n",
    "print(\"Shape of test_data\\t\\t\",test_data.shape)\n",
    "print(\"Shape of test_labels\\t\\t\",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Pnn8cUXqkO0-",
    "outputId": "e8d29082-0bbd-4984-dd06-50f2e3825666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of test_data (10000, 784)\n",
      "New shape of train_data (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize test and training data\n",
    "test_data = test_data.reshape(test_data.shape[0], test_data.shape[1] * test_data.shape[2]).astype('float32')\n",
    "train_data = train_data.reshape(train_data.shape[0], train_data.shape[1] * train_data.shape[2]).astype('float32')\n",
    "\n",
    "print('New shape of test_data', test_data.shape)\n",
    "print('New shape of train_data', train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC - State Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for SVC on MNIST\n",
    "parameters = {\n",
    "    'kernel': ['poly', 'rbf', 'sigmoid'],\n",
    "    'C':[0.001, 0.1, 100, 10e5],\n",
    "    'gamma':[10,1,0.1,0.01]\n",
    "}\n",
    "grid_svc = GridSearchCV(svm.SVC(), param_grid=parameters, cv=3, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_svc.fit(train_data[:10000], train_labels[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_svc.score(test_data, test_labels))\n",
    "print(grid_svc.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_svc.cv_results_)\n",
    "df.to_pickle('mnist_svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D94DaDepjA9n"
   },
   "outputs": [],
   "source": [
    "# Random Forests, grid search to find best parameter and run cross validation\n",
    "parameters = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "}\n",
    "grid_rfc = GridSearchCV(RandomForestClassifier(), param_grid=parameters, cv=2, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rfc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696\n",
      "{'max_depth': 80, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(grid_rfc.score(test_data, test_labels))\n",
    "print(grid_rfc.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_rfc.cv_results_)\n",
    "df.to_pickle('mnist_rfc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>25.584607</td>\n",
       "      <td>0.942350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>34.939611</td>\n",
       "      <td>0.961650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>36.224180</td>\n",
       "      <td>0.961817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>36.129935</td>\n",
       "      <td>0.961550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>39.031673</td>\n",
       "      <td>0.961400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>39.911803</td>\n",
       "      <td>0.961850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>39.959677</td>\n",
       "      <td>0.962167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>39.967157</td>\n",
       "      <td>0.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>35.783377</td>\n",
       "      <td>0.961567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>31.846899</td>\n",
       "      <td>0.961567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>31.591581</td>\n",
       "      <td>0.962200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth  mean_fit_time  mean_test_score\n",
       "0                 100              10      25.584607         0.942350\n",
       "1                 100              20      34.939611         0.961650\n",
       "2                 100              30      36.224180         0.961817\n",
       "3                 100              40      36.129935         0.961550\n",
       "4                 100              50      39.031673         0.961400\n",
       "5                 100              60      39.911803         0.961850\n",
       "6                 100              70      39.959677         0.962167\n",
       "7                 100              80      39.967157         0.962500\n",
       "8                 100              90      35.783377         0.961567\n",
       "9                 100             100      31.846899         0.961567\n",
       "10                100             110      31.591581         0.962200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('mnist_rfc.pkl')\n",
    "df[['param_n_estimators','param_max_depth', 'mean_fit_time', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JaN6gTMjBgX"
   },
   "outputs": [],
   "source": [
    "# Linear Classifier\n",
    "parameters = {\n",
    "    'solver': ['sag', 'lbfgs'],\n",
    "    'multi_class': ['ovr']\n",
    "}\n",
    "grid_lr = GridSearchCV(LogisticRegression(), param_grid=parameters, cv=2, n_jobs=-1, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikhi\\appdata\\local\\conda\\conda\\envs\\ml-class\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'solver': ['sag', 'lbfgs'], 'multi_class': ['ovr']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9201\n",
      "{'multi_class': 'ovr', 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_lr.score(test_data, test_labels))\n",
    "print(grid_lr.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_lr.cv_results_)\n",
    "df.to_pickle('mnist_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sag</td>\n",
       "      <td>ovr</td>\n",
       "      <td>382.959543</td>\n",
       "      <td>0.911417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>ovr</td>\n",
       "      <td>97.299586</td>\n",
       "      <td>0.911383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_solver param_multi_class  mean_fit_time  mean_test_score\n",
       "0          sag               ovr     382.959543         0.911417\n",
       "1        lbfgs               ovr      97.299586         0.911383"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('mnist_lr.pkl')\n",
    "df[['param_solver','param_multi_class', 'mean_fit_time', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_l_tpUBjIX3"
   },
   "outputs": [],
   "source": [
    "# Neural Nets\n",
    "parameters = {\n",
    "    'activation': ['logistic'],\n",
    "    'solver': ['sgd'],\n",
    "    'max_iter': [100],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'hidden_layer_sizes': [(10, 15), (100, 150), (550, 200)]\n",
    "}\n",
    "grid_nn = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nn.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5SH7u0k4GM7b",
    "outputId": "8762beb2-299f-4d70-b637-11408ae9fa9c"
   },
   "outputs": [],
   "source": [
    "print(grid_nn.score(test_data, test_labels))\n",
    "print(grid_nn.best_params_)\n",
    "\n",
    "df = pd.DataFrame(grid_nn.cv_results_)\n",
    "df.to_pickle('mnist_nn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_learning_rate_init</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(10, 15)</td>\n",
       "      <td>120.627461</td>\n",
       "      <td>0.663233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(10, 15)</td>\n",
       "      <td>122.322817</td>\n",
       "      <td>0.921450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(100, 150)</td>\n",
       "      <td>442.548446</td>\n",
       "      <td>0.836833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(100, 150)</td>\n",
       "      <td>446.719322</td>\n",
       "      <td>0.954433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>(550, 200)</td>\n",
       "      <td>1911.675161</td>\n",
       "      <td>0.866133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>(550, 200)</td>\n",
       "      <td>1900.752605</td>\n",
       "      <td>0.938700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_learning_rate_init param_hidden_layer_sizes  mean_fit_time  \\\n",
       "0                    0.001                 (10, 15)     120.627461   \n",
       "1                     0.01                 (10, 15)     122.322817   \n",
       "2                    0.001               (100, 150)     442.548446   \n",
       "3                     0.01               (100, 150)     446.719322   \n",
       "4                    0.001               (550, 200)    1911.675161   \n",
       "5                     0.01               (550, 200)    1900.752605   \n",
       "\n",
       "   mean_test_score  \n",
       "0         0.663233  \n",
       "1         0.921450  \n",
       "2         0.836833  \n",
       "3         0.954433  \n",
       "4         0.866133  \n",
       "5         0.938700  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('mnist_nn.pkl')\n",
    "df[['param_learning_rate_init','param_hidden_layer_sizes', 'mean_fit_time', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Q:</b> Which algorithm (and the corresponding settings) performs best?<br>\n",
    "<b>A:</b>\n",
    "For the various settings tried above, best performance is given by\n",
    "<br><br>\n",
    "\n",
    "<b>Q:</b> Which algorithm was easiest to tune?<br>\n",
    "<b>A:</b>\n",
    "Random forest classifier took least time to tune as compared to other algorithms and presented with a accuracy of 96.96%\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<b>Q:</b> Be sure to show the various hyperparameter settings you tried. <br>\n",
    "<b>A:</b>\n",
    "Hyperparameter settings are shown in parameters variable under each algorithm used.\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<b>Q:</b> For each algorithm, describe what you learnt from the various experiments.<br>\n",
    "<b>A:</b> Our findings for each algorithm:<br>\n",
    "<b>State Vector Classifier</b>:\n",
    "- Best accuracy of SVC is  \n",
    "- It took a lot of time for svc classifier to classify on whole dataset.\n",
    "\n",
    "\n",
    "<b>Random Forest Classifier</b>:\n",
    "- Best accuracy is: 96.96%\n",
    "- Best config is {'max_depth': 80, 'n_estimators': 100}.\n",
    "- Random forest classifier classifies mnist based on various decision trees. As 80 depth tree is producing the best results that can signify that out of 784 dimensions, decisions on 80 different dimensions can successfully classify digits.\n",
    "\n",
    "<b>Linear Classifier</b>:\n",
    "- Best accuracy is: 92.01 %\n",
    "- Best config is {'multi_class': 'ovr', 'solver': 'sag'}\n",
    "- Linear classifier for mnist data has lowest accuracy among its peers. Although it is above 90%.\n",
    "- This signifies that in 784 dimensions their exists hyperplanes that can successfully classify various digits in the data.\n",
    "\n",
    "<b>Neural Network</b>:\n",
    "- Neural Networks best accuracy is of 97.15%. \n",
    "- Best config is {'activation': 'logistic', 'hidden_layer_sizes': (100,150), 'learning_rate_init':0.01,, 'max_iter': 100, 'solver': 'sgd'}.\n",
    "- It takes a long time to classify mnist data using neural networks.\n",
    "- For neural networks, two hidden layers works best for mnist data. \n",
    "<br><br>\n",
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A3_B00809791.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
